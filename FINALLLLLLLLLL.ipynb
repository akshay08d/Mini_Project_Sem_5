{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Sentiment Classification Using Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ùêÅùêöùê≤ùêûùê¨ ùêìùê°ùêûùê®ùê´ùêûùê¶  is just a probablity theorem the statement that  is :\n",
    "###### P = probablity\n",
    "###### P(a/b) = probablity of 'a' when 'b' has occured.\n",
    "ùëù(ùê¥|ùêµ)‚ãÖùëù(ùêµ)=ùëù(ùêµ|ùê¥)‚ãÖùëù(ùê¥)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing required libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\pandas\\compat\\__init__.py:124: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#Load the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re,string,unicodedata\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #  Loading the dataset into df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5791, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user I'd be afraid to short AMZN - they are lo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNTA Over 12.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OI  Over 21.37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PGNX  Over 3.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AAP - user if so then the current downtrend wi...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Monday's relative weakness. NYX WIN TIE TAP IC...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GOOG - ower trend line channel test &amp; volume s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AAP will watch tomorrow for ONG entry.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Sentiment\n",
       "0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...          1\n",
       "1  user: AAP MOVIE. 55% return for the FEA/GEED i...          1\n",
       "2  user I'd be afraid to short AMZN - they are lo...          1\n",
       "3                                  MNTA Over 12.00            1\n",
       "4                                   OI  Over 21.37            1\n",
       "5                                  PGNX  Over 3.04            1\n",
       "6  AAP - user if so then the current downtrend wi...         -1\n",
       "7  Monday's relative weakness. NYX WIN TIE TAP IC...         -1\n",
       "8  GOOG - ower trend line channel test & volume s...          1\n",
       "9             AAP will watch tomorrow for ONG entry.          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing the training datafile\n",
    "\n",
    "df=pd.read_csv(r'stock_data.csv')\n",
    "print(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objects of stocks_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sentiment',\n",
       " 'T',\n",
       " 'Text',\n",
       " '_AXIS_LEN',\n",
       " '_AXIS_ORDERS',\n",
       " '_AXIS_REVERSED',\n",
       " '_AXIS_TO_AXIS_NUMBER',\n",
       " '_HANDLED_TYPES',\n",
       " '__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__annotations__',\n",
       " '__array__',\n",
       " '__array_priority__',\n",
       " '__array_ufunc__',\n",
       " '__array_wrap__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__divmod__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__finalize__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__iand__',\n",
       " '__ifloordiv__',\n",
       " '__imod__',\n",
       " '__imul__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__invert__',\n",
       " '__ior__',\n",
       " '__ipow__',\n",
       " '__isub__',\n",
       " '__iter__',\n",
       " '__itruediv__',\n",
       " '__ixor__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__matmul__',\n",
       " '__mod__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__or__',\n",
       " '__pos__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rand__',\n",
       " '__rdivmod__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rfloordiv__',\n",
       " '__rmatmul__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__ror__',\n",
       " '__round__',\n",
       " '__rpow__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__rxor__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__weakref__',\n",
       " '__xor__',\n",
       " '_accessors',\n",
       " '_accum_func',\n",
       " '_add_numeric_operations',\n",
       " '_agg_by_level',\n",
       " '_agg_examples_doc',\n",
       " '_agg_summary_and_see_also_doc',\n",
       " '_align_frame',\n",
       " '_align_series',\n",
       " '_arith_method',\n",
       " '_as_manager',\n",
       " '_attrs',\n",
       " '_box_col_values',\n",
       " '_can_fast_transpose',\n",
       " '_check_inplace_and_allows_duplicate_labels',\n",
       " '_check_inplace_setting',\n",
       " '_check_is_chained_assignment_possible',\n",
       " '_check_label_or_level_ambiguity',\n",
       " '_check_setitem_copy',\n",
       " '_clear_item_cache',\n",
       " '_clip_with_one_bound',\n",
       " '_clip_with_scalar',\n",
       " '_cmp_method',\n",
       " '_combine_frame',\n",
       " '_consolidate',\n",
       " '_consolidate_inplace',\n",
       " '_construct_axes_dict',\n",
       " '_construct_axes_from_arguments',\n",
       " '_construct_result',\n",
       " '_constructor',\n",
       " '_constructor_sliced',\n",
       " '_convert',\n",
       " '_count_level',\n",
       " '_data',\n",
       " '_dir_additions',\n",
       " '_dir_deletions',\n",
       " '_dispatch_frame_op',\n",
       " '_drop_axis',\n",
       " '_drop_labels_or_levels',\n",
       " '_ensure_valid_index',\n",
       " '_find_valid_index',\n",
       " '_flags',\n",
       " '_from_arrays',\n",
       " '_from_mgr',\n",
       " '_get_agg_axis',\n",
       " '_get_axis',\n",
       " '_get_axis_name',\n",
       " '_get_axis_number',\n",
       " '_get_axis_resolvers',\n",
       " '_get_block_manager_axis',\n",
       " '_get_bool_data',\n",
       " '_get_cleaned_column_resolvers',\n",
       " '_get_column_array',\n",
       " '_get_index_resolvers',\n",
       " '_get_item_cache',\n",
       " '_get_label_or_level_values',\n",
       " '_get_numeric_data',\n",
       " '_get_value',\n",
       " '_getitem_bool_array',\n",
       " '_getitem_multilevel',\n",
       " '_gotitem',\n",
       " '_hidden_attrs',\n",
       " '_indexed_same',\n",
       " '_info_axis',\n",
       " '_info_axis_name',\n",
       " '_info_axis_number',\n",
       " '_info_repr',\n",
       " '_init_mgr',\n",
       " '_inplace_method',\n",
       " '_internal_names',\n",
       " '_internal_names_set',\n",
       " '_is_copy',\n",
       " '_is_homogeneous_type',\n",
       " '_is_label_or_level_reference',\n",
       " '_is_label_reference',\n",
       " '_is_level_reference',\n",
       " '_is_mixed_type',\n",
       " '_is_view',\n",
       " '_iset_item',\n",
       " '_iset_item_mgr',\n",
       " '_iset_not_inplace',\n",
       " '_item_cache',\n",
       " '_iter_column_arrays',\n",
       " '_ixs',\n",
       " '_join_compat',\n",
       " '_logical_func',\n",
       " '_logical_method',\n",
       " '_maybe_cache_changed',\n",
       " '_maybe_update_cacher',\n",
       " '_metadata',\n",
       " '_mgr',\n",
       " '_min_count_stat_function',\n",
       " '_needs_reindex_multi',\n",
       " '_protect_consolidate',\n",
       " '_reduce',\n",
       " '_reindex_axes',\n",
       " '_reindex_columns',\n",
       " '_reindex_index',\n",
       " '_reindex_multi',\n",
       " '_reindex_with_indexers',\n",
       " '_replace_columnwise',\n",
       " '_repr_data_resource_',\n",
       " '_repr_fits_horizontal_',\n",
       " '_repr_fits_vertical_',\n",
       " '_repr_html_',\n",
       " '_repr_latex_',\n",
       " '_reset_cache',\n",
       " '_reset_cacher',\n",
       " '_sanitize_column',\n",
       " '_series',\n",
       " '_set_axis',\n",
       " '_set_axis_name',\n",
       " '_set_axis_nocheck',\n",
       " '_set_is_copy',\n",
       " '_set_item',\n",
       " '_set_item_frame_value',\n",
       " '_set_item_mgr',\n",
       " '_set_value',\n",
       " '_setitem_array',\n",
       " '_setitem_frame',\n",
       " '_setitem_slice',\n",
       " '_slice',\n",
       " '_stat_axis',\n",
       " '_stat_axis_name',\n",
       " '_stat_axis_number',\n",
       " '_stat_function',\n",
       " '_stat_function_ddof',\n",
       " '_take_with_is_copy',\n",
       " '_to_dict_of_blocks',\n",
       " '_typ',\n",
       " '_update_inplace',\n",
       " '_validate_dtype',\n",
       " '_values',\n",
       " '_where',\n",
       " 'abs',\n",
       " 'add',\n",
       " 'add_prefix',\n",
       " 'add_suffix',\n",
       " 'agg',\n",
       " 'aggregate',\n",
       " 'align',\n",
       " 'all',\n",
       " 'any',\n",
       " 'append',\n",
       " 'apply',\n",
       " 'applymap',\n",
       " 'asfreq',\n",
       " 'asof',\n",
       " 'assign',\n",
       " 'astype',\n",
       " 'at',\n",
       " 'at_time',\n",
       " 'attrs',\n",
       " 'axes',\n",
       " 'backfill',\n",
       " 'between_time',\n",
       " 'bfill',\n",
       " 'bool',\n",
       " 'boxplot',\n",
       " 'clip',\n",
       " 'columns',\n",
       " 'combine',\n",
       " 'combine_first',\n",
       " 'compare',\n",
       " 'convert_dtypes',\n",
       " 'copy',\n",
       " 'corr',\n",
       " 'corrwith',\n",
       " 'count',\n",
       " 'cov',\n",
       " 'cummax',\n",
       " 'cummin',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'describe',\n",
       " 'diff',\n",
       " 'div',\n",
       " 'divide',\n",
       " 'dot',\n",
       " 'drop',\n",
       " 'drop_duplicates',\n",
       " 'droplevel',\n",
       " 'dropna',\n",
       " 'dtypes',\n",
       " 'duplicated',\n",
       " 'empty',\n",
       " 'eq',\n",
       " 'equals',\n",
       " 'eval',\n",
       " 'ewm',\n",
       " 'expanding',\n",
       " 'explode',\n",
       " 'ffill',\n",
       " 'fillna',\n",
       " 'filter',\n",
       " 'first',\n",
       " 'first_valid_index',\n",
       " 'flags',\n",
       " 'floordiv',\n",
       " 'from_dict',\n",
       " 'from_records',\n",
       " 'ge',\n",
       " 'get',\n",
       " 'groupby',\n",
       " 'gt',\n",
       " 'head',\n",
       " 'hist',\n",
       " 'iat',\n",
       " 'idxmax',\n",
       " 'idxmin',\n",
       " 'iloc',\n",
       " 'index',\n",
       " 'infer_objects',\n",
       " 'info',\n",
       " 'insert',\n",
       " 'interpolate',\n",
       " 'isin',\n",
       " 'isna',\n",
       " 'isnull',\n",
       " 'items',\n",
       " 'iteritems',\n",
       " 'iterrows',\n",
       " 'itertuples',\n",
       " 'join',\n",
       " 'keys',\n",
       " 'kurt',\n",
       " 'kurtosis',\n",
       " 'last',\n",
       " 'last_valid_index',\n",
       " 'le',\n",
       " 'loc',\n",
       " 'lookup',\n",
       " 'lt',\n",
       " 'mad',\n",
       " 'mask',\n",
       " 'max',\n",
       " 'mean',\n",
       " 'median',\n",
       " 'melt',\n",
       " 'memory_usage',\n",
       " 'merge',\n",
       " 'min',\n",
       " 'mod',\n",
       " 'mode',\n",
       " 'mul',\n",
       " 'multiply',\n",
       " 'ndim',\n",
       " 'ne',\n",
       " 'nlargest',\n",
       " 'notna',\n",
       " 'notnull',\n",
       " 'nsmallest',\n",
       " 'nunique',\n",
       " 'pad',\n",
       " 'pct_change',\n",
       " 'pipe',\n",
       " 'pivot',\n",
       " 'pivot_table',\n",
       " 'plot',\n",
       " 'pop',\n",
       " 'pow',\n",
       " 'prod',\n",
       " 'product',\n",
       " 'quantile',\n",
       " 'query',\n",
       " 'radd',\n",
       " 'rank',\n",
       " 'rdiv',\n",
       " 'reindex',\n",
       " 'reindex_like',\n",
       " 'rename',\n",
       " 'rename_axis',\n",
       " 'reorder_levels',\n",
       " 'replace',\n",
       " 'resample',\n",
       " 'reset_index',\n",
       " 'rfloordiv',\n",
       " 'rmod',\n",
       " 'rmul',\n",
       " 'rolling',\n",
       " 'round',\n",
       " 'rpow',\n",
       " 'rsub',\n",
       " 'rtruediv',\n",
       " 'sample',\n",
       " 'select_dtypes',\n",
       " 'sem',\n",
       " 'set_axis',\n",
       " 'set_flags',\n",
       " 'set_index',\n",
       " 'shape',\n",
       " 'shift',\n",
       " 'size',\n",
       " 'skew',\n",
       " 'slice_shift',\n",
       " 'sort_index',\n",
       " 'sort_values',\n",
       " 'squeeze',\n",
       " 'stack',\n",
       " 'std',\n",
       " 'style',\n",
       " 'sub',\n",
       " 'subtract',\n",
       " 'sum',\n",
       " 'swapaxes',\n",
       " 'swaplevel',\n",
       " 'tail',\n",
       " 'take',\n",
       " 'to_clipboard',\n",
       " 'to_csv',\n",
       " 'to_dict',\n",
       " 'to_excel',\n",
       " 'to_feather',\n",
       " 'to_gbq',\n",
       " 'to_hdf',\n",
       " 'to_html',\n",
       " 'to_json',\n",
       " 'to_latex',\n",
       " 'to_markdown',\n",
       " 'to_numpy',\n",
       " 'to_parquet',\n",
       " 'to_period',\n",
       " 'to_pickle',\n",
       " 'to_records',\n",
       " 'to_sql',\n",
       " 'to_stata',\n",
       " 'to_string',\n",
       " 'to_timestamp',\n",
       " 'to_xarray',\n",
       " 'to_xml',\n",
       " 'transform',\n",
       " 'transpose',\n",
       " 'truediv',\n",
       " 'truncate',\n",
       " 'tz_convert',\n",
       " 'tz_localize',\n",
       " 'unstack',\n",
       " 'update',\n",
       " 'value_counts',\n",
       " 'values',\n",
       " 'var',\n",
       " 'where',\n",
       " 'xs']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dir(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bar Graph representation of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"Sentiment\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    3685\n",
       "-1    2106\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sentiment count\n",
    "df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing the headline of news and setting stop words of english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization of text\n",
    "tokenizer=ToktokTokenizer()\n",
    "#Setting English stopwords\n",
    "stopword_list=nltk.corpus.stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopword_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing text cleaning on our headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing the square brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing the noisy text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_text(text):\n",
    "    text = remove_between_square_brackets(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applyte  function on Text column / headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text']=df['Text'].apply(denoise_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define function for removing special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(text, remove_digits=True):\n",
    "    pattern=r'[^a-zA-z0-9\\s]'\n",
    "    text=re.sub(pattern,'',text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #Apply function on review column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text']=df['Text'].apply(remove_special_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset after text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user AAP MOVIE 55 return for the FEAGEED indic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user Id be afraid to short AMZN  they are look...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNTA Over 1200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OI  Over 2137</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5786</th>\n",
       "      <td>Industry body CII said discoms are likely to s...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5787</th>\n",
       "      <td>Gold prices slip below Rs 46000 as investors b...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5788</th>\n",
       "      <td>Workers at Bajaj Auto have agreed to a 10 wage...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5789</th>\n",
       "      <td>Sharemarket LIVE Sensex off days high up 600 p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5790</th>\n",
       "      <td>Sensex Nifty climb off days highs still up 2 K...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5791 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Sentiment\n",
       "0     Kickers on my watchlist XIDE TIT SOQ PNK CPW B...          1\n",
       "1     user AAP MOVIE 55 return for the FEAGEED indic...          1\n",
       "2     user Id be afraid to short AMZN  they are look...          1\n",
       "3                                      MNTA Over 1200            1\n",
       "4                                       OI  Over 2137            1\n",
       "...                                                 ...        ...\n",
       "5786  Industry body CII said discoms are likely to s...         -1\n",
       "5787  Gold prices slip below Rs 46000 as investors b...         -1\n",
       "5788  Workers at Bajaj Auto have agreed to a 10 wage...          1\n",
       "5789  Sharemarket LIVE Sensex off days high up 600 p...          1\n",
       "5790  Sensex Nifty climb off days highs still up 2 K...          1\n",
       "\n",
       "[5791 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing the stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply function on Sentiment column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text']=df['Text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into training and testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test size = 30% and Random state is at 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_Train = df['Text']\n",
    "y_Train = df['Sentiment']\n",
    "x_Train, x_test, y_Train, y_test = train_test_split(x_Train,y_Train, stratify=y_Train, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing  headlines text  to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(stop_words='english')\n",
    "x_Train = vec.fit_transform(x_Train).toarray()\n",
    "x_test = vec.transform(x_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The Naive Bayes Classifier is an algorithm that encodes this simple reasoning process mathematically. It is based on two important pieces of information that we can learn from the training set:\n",
    "######  The probabilities that a randomly chosen review will be positive, or negative\n",
    "###### How likely is it that a given token would appear in a positive or negative review\n",
    "###### This is all the information we need to build a model capable of predicting fairly accurately how any given review will be classified, given its text!¬∂"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using multinomial naive bayes on our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(x_Train, y_Train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Applying  ùêÅùêöùê≤ùêûùê¨ ùêìùê°ùêûùê®ùê´ùêûùê¶  to our Headline sentiment problem:\n",
    "\n",
    "###### We identify  ùê¥  and  ùêµ  as\n",
    "###### ùê¥ = class , i.e. positive or negative, and\n",
    "###### ùêµ = tokens , wordof text\n",
    "\n",
    "###### Then  ùêÅùêöùê≤ùêûùê¨ ùêìùê°ùêûùê®ùê´ùêûùê¶  says\n",
    "\n",
    "###### ùëù(class|tokens)‚ãÖùëù(tokens)=ùëù(tokens|class)‚ãÖùëù(class) \n",
    "###### so that\n",
    "###### ùëù(class|tokens)=ùëù(tokens|class)‚ãÖùëù(class)ùëù(tokens) \n",
    "###### Since  ùëù(tokens)  is a constant, we have the proportionality\n",
    "\n",
    "###### ùëù(class|tokens)‚àùùëù(tokens|class)‚ãÖùëù(class) \n",
    "###### The left hand side of the above expression is called the  ùê©ùê®ùê¨ùê≠ùêûùê´ùê¢ùê®ùê´ ùêúùê•ùêöùê¨ùê¨ ùê©ùê´ùê®ùêõùêöùêõùê¢ùê•ùê¢ùê≠ùê≤ , the probability that the review is positive (or negative), given the tokens it contains. This is exactly what we want to predict!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of model is at 77%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7756041426927502"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Naive Bayes classifier is a collection of many algorithms where all the algorithms share one common principle, and that is each feature being classified is not related to any other feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy can be further increased by using larger dataset, more exclusive (words/tokens), analysing tokens more deeply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
